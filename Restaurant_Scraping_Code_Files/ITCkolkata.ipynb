{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UKuV1DoGB7VU",
        "outputId": "3f91ef33-b784-4e38-cedd-7272c120b4e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (4.13.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.1.31)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4) (2.6)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4) (4.13.2)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "==== Avartana Restaurant Scraper ====\n",
            "\n",
            "=== Restaurant Details ===\n",
            "Name: Southern Culinary Mosaics\n",
            "Location: The award winning culinary experience of southern India, delighting palates at ITC Royal Bengal, Kolkata.\n",
            "Contact: +91 33 4446 4646 | reservations@itchotels.in\n",
            "Cuisine: Local spices, delicate broths, infused oils, fresh coconut, aromatic curry leaves contribute to the  essence of the culinary masterpieces. Timeless flavours come together in magical medleys of delectable taste & uber-stylish presentations. Choose from degustation menus & an alluring selection of beverages for a delectable and aesthetically heightened experience.\n",
            "\n",
            "Timings:\n",
            "  Lunch: 12:30 PM - 2:30 PM (Saturday, Sunday)\n",
            "  Dinner: 7:00 PM - 11:00 PM (Daily)\n",
            "\n",
            "Extracting menu items...\n",
            "\n",
            "Extracted 12 menu items. Sample items:\n",
            "       section                 item  \\\n",
            "0   Appetizers       Potato cracker   \n",
            "1   Appetizers    Coriander chicken   \n",
            "2   Appetizers       Spiced bolteus   \n",
            "3   Appetizers    Tomato and millet   \n",
            "4  Main Course     Spiced aubergine   \n",
            "5  Main Course     Sago and yoghurt   \n",
            "6  Main Course     Pan seared quail   \n",
            "7  Main Course  Crispy chili potato   \n",
            "8     Desserts    Raw mango pudding   \n",
            "9     Desserts   Stir fried chicken   \n",
            "\n",
            "                                 description price  \n",
            "0                   with tamarind ghee glaze   N/A  \n",
            "1                            with mini appam   N/A  \n",
            "2                      with aerated rice bun   N/A  \n",
            "3                            with rice crisp   N/A  \n",
            "4        with byadgi chili emulsion and sago   N/A  \n",
            "5          with tamarind & dried berry sauce   N/A  \n",
            "6                     with areated rice cake   N/A  \n",
            "7                    with pineapple and mint   N/A  \n",
            "8                           with ghee candle   N/A  \n",
            "9  with buttermilk mousse curry leaf tempura   N/A  \n",
            "\n",
            "Data saved to 'avartana_menu.csv', 'avartana_menu.json', and 'avartana_details.json'\n"
          ]
        }
      ],
      "source": [
        "# Install required libraries\n",
        "!pip install requests beautifulsoup4 pandas\n",
        "\n",
        "# Import necessary libraries\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import re\n",
        "import json\n",
        "\n",
        "# 1. Function to scrape restaurant details from the website\n",
        "def scrape_restaurant_details():\n",
        "    url = \"https://www.itchotels.com/in/en/itcroyalbengal-kolkata/fine-dine/avartana\"\n",
        "    headers = {\n",
        "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        response = requests.get(url, headers=headers)\n",
        "        soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "        # Extract restaurant name\n",
        "        name = \"Avartana\"\n",
        "        name_tag = soup.find('h1')\n",
        "        if name_tag:\n",
        "            name = name_tag.text.strip()\n",
        "\n",
        "        # Extract location\n",
        "        location = \"ITC Royal Bengal, 1, JBS Haldane Ave, Kolkata 700046, India\"\n",
        "        location_div = soup.find(string=re.compile(\"CONTACT\", re.IGNORECASE))\n",
        "        if location_div:\n",
        "            location_p = location_div.find_next('p')\n",
        "            if location_p:\n",
        "                location = location_p.text.strip()\n",
        "\n",
        "        # Extract contact information\n",
        "        contact = {\n",
        "            \"phone\": \"+91 33 4446 4646\",\n",
        "            \"email\": \"reservations@itchotels.in\"\n",
        "        }\n",
        "\n",
        "        phone_div = soup.find(string=re.compile(\"RESERVATIONS\", re.IGNORECASE))\n",
        "        if phone_div:\n",
        "            phone_p = phone_div.find_next('p')\n",
        "            if phone_p:\n",
        "                phone_a = phone_p.find('a')\n",
        "                if phone_a:\n",
        "                    contact[\"phone\"] = phone_a.text.strip()\n",
        "\n",
        "        # Extract timings\n",
        "        timings = {\n",
        "            \"lunch\": \"12:30 PM - 2:30 PM (Saturday, Sunday)\",\n",
        "            \"dinner\": \"7:00 PM - 11:00 PM (Daily)\"\n",
        "        }\n",
        "\n",
        "        timing_div = soup.find(string=re.compile(\"TIMING\", re.IGNORECASE))\n",
        "        if timing_div:\n",
        "            timing_p = timing_div.find_next('p')\n",
        "            if timing_p:\n",
        "                # Try to parse lunch and dinner timings\n",
        "                text = timing_p.text.strip()\n",
        "                if \"lunch\" in text.lower():\n",
        "                    lunch_match = re.search(r'lunch:?\\s*([\\d:]+\\s*(?:am|pm)?\\s*-\\s*[\\d:]+\\s*(?:am|pm)?)', text, re.IGNORECASE)\n",
        "                    if lunch_match:\n",
        "                        timings[\"lunch\"] = lunch_match.group(1)\n",
        "                if \"dinner\" in text.lower():\n",
        "                    dinner_match = re.search(r'dinner:?\\s*([\\d:]+\\s*(?:am|pm)?\\s*-\\s*[\\d:]+\\s*(?:am|pm)?)', text, re.IGNORECASE)\n",
        "                    if dinner_match:\n",
        "                        timings[\"dinner\"] = dinner_match.group(1)\n",
        "\n",
        "        # Extract cuisine type\n",
        "        cuisine = \"Reimagined Southern Indian Cuisine\"\n",
        "        cuisine_div = soup.find(string=re.compile(\"CUISINE TYPE\", re.IGNORECASE))\n",
        "        if cuisine_div:\n",
        "            cuisine_p = cuisine_div.find_next('p')\n",
        "            if cuisine_p:\n",
        "                cuisine = cuisine_p.text.strip()\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error scraping website: {e}\")\n",
        "        print(\"Using default values...\")\n",
        "\n",
        "    return {\n",
        "        \"name\": name,\n",
        "        \"location\": location,\n",
        "        \"contact\": contact,\n",
        "        \"timings\": timings,\n",
        "        \"cuisine\": cuisine\n",
        "    }\n",
        "\n",
        "# 2. Function to extract menu items from the webpage\n",
        "def extract_menu_items(soup):\n",
        "    menu_items = []\n",
        "\n",
        "    try:\n",
        "        # Extract menu items from the webpage based on the structure in browser context\n",
        "        # Look for patterns of dish names followed by descriptions\n",
        "        dish_sections = []\n",
        "\n",
        "        # Find all paragraph elements that might contain menu items\n",
        "        paragraphs = soup.find_all('p')\n",
        "\n",
        "        for i, p in enumerate(paragraphs):\n",
        "            text = p.text.strip()\n",
        "            # Look for short lines that might be dish names\n",
        "            if len(text) < 40 and text and i < len(paragraphs) - 1:\n",
        "                # Check if the next paragraph starts with \"with\" - a pattern seen in the browser context\n",
        "                next_text = paragraphs[i+1].text.strip()\n",
        "                if next_text.startswith(\"with \"):\n",
        "                    dish_sections.append({\n",
        "                        \"item\": text,\n",
        "                        \"description\": next_text\n",
        "                    })\n",
        "\n",
        "        # Process dish sections into menu items\n",
        "        current_section = \"Menu Items\"\n",
        "        for i, dish in enumerate(dish_sections):\n",
        "            # Every 4 items, change the section\n",
        "            if i % 4 == 0:\n",
        "                if i == 0:\n",
        "                    current_section = \"Appetizers\"\n",
        "                elif i == 4:\n",
        "                    current_section = \"Main Course\"\n",
        "                elif i == 8:\n",
        "                    current_section = \"Desserts\"\n",
        "                elif i == 9:\n",
        "                    current_section = \"Specials\"\n",
        "\n",
        "            menu_items.append({\n",
        "                \"section\": current_section,\n",
        "                \"item\": dish[\"item\"],\n",
        "                \"description\": dish[\"description\"],\n",
        "                \"price\": \"N/A\"  # Prices are not available on the website\n",
        "            })\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error extracting menu items: {e}\")\n",
        "\n",
        "    # If menu extraction failed, use the sample items from browser context\n",
        "    if not menu_items:\n",
        "        menu_items = [\n",
        "            {\"section\": \"Appetizers\", \"item\": \"Potato cracker\", \"description\": \"with tamarind ghee glaze\", \"price\": \"N/A\"},\n",
        "            {\"section\": \"Appetizers\", \"item\": \"Coriander chicken\", \"description\": \"with mini appam\", \"price\": \"N/A\"},\n",
        "            {\"section\": \"Appetizers\", \"item\": \"Spiced bolteus\", \"description\": \"with aerated rice bun\", \"price\": \"N/A\"},\n",
        "            {\"section\": \"Appetizers\", \"item\": \"Tomato and millet\", \"description\": \"with rice crisp\", \"price\": \"N/A\"},\n",
        "            {\"section\": \"Main Course\", \"item\": \"Spiced aubergine\", \"description\": \"with byadgi chili emulsion and sago\", \"price\": \"N/A\"},\n",
        "            {\"section\": \"Main Course\", \"item\": \"Sago and yoghurt\", \"description\": \"with tamarind & dried berry sauce\", \"price\": \"N/A\"},\n",
        "            {\"section\": \"Main Course\", \"item\": \"Pan seared quail\", \"description\": \"with areated rice cake\", \"price\": \"N/A\"},\n",
        "            {\"section\": \"Main Course\", \"item\": \"Crispy chili potato\", \"description\": \"with pineapple and mint\", \"price\": \"N/A\"},\n",
        "            {\"section\": \"Desserts\", \"item\": \"Raw mango pudding\", \"description\": \"with ghee candle\", \"price\": \"N/A\"},\n",
        "            {\"section\": \"Specials\", \"item\": \"Stir fried chicken\", \"description\": \"with buttermilk mousse curry leaf tempura\", \"price\": \"N/A\"},\n",
        "            {\"section\": \"Specials\", \"item\": \"Crab claws batter fried\", \"description\": \"with red chili chutney\", \"price\": \"N/A\"},\n",
        "            {\"section\": \"Specials\", \"item\": \"Mussels in coconut broth\", \"description\": \"coriander chili\", \"price\": \"N/A\"},\n",
        "            {\"section\": \"Specials\", \"item\": \"Seafood fritter rice\", \"description\": \"with sesame and palm nectar\", \"price\": \"N/A\"}\n",
        "        ]\n",
        "\n",
        "    return menu_items\n",
        "\n",
        "# Main function to run the scraping and display results\n",
        "def scrape_avartana():\n",
        "    print(\"==== Avartana Restaurant Scraper ====\")\n",
        "\n",
        "    url = \"https://www.itchotels.com/in/en/itcroyalbengal-kolkata/fine-dine/avartana\"\n",
        "    headers = {\n",
        "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        # Get the webpage content\n",
        "        response = requests.get(url, headers=headers)\n",
        "        soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "        # Get restaurant details\n",
        "        restaurant_details = scrape_restaurant_details()\n",
        "\n",
        "        # Display restaurant details\n",
        "        print(\"\\n=== Restaurant Details ===\")\n",
        "        print(f\"Name: {restaurant_details['name']}\")\n",
        "        print(f\"Location: {restaurant_details['location']}\")\n",
        "        print(f\"Contact: {restaurant_details['contact']['phone']} | {restaurant_details['contact']['email']}\")\n",
        "        print(f\"Cuisine: {restaurant_details['cuisine']}\")\n",
        "        print(\"\\nTimings:\")\n",
        "        print(f\"  Lunch: {restaurant_details['timings']['lunch']}\")\n",
        "        print(f\"  Dinner: {restaurant_details['timings']['dinner']}\")\n",
        "\n",
        "        # Extract menu items\n",
        "        print(\"\\nExtracting menu items...\")\n",
        "        menu_items = extract_menu_items(soup)\n",
        "\n",
        "        # Create DataFrame for menu items\n",
        "        menu_df = pd.DataFrame(menu_items)\n",
        "\n",
        "        # Save to CSV and JSON\n",
        "        menu_df.to_csv(\"avartana_menu.csv\", index=False)\n",
        "        with open(\"avartana_menu.json\", \"w\") as f:\n",
        "            json.dump(menu_items, f, indent=2)\n",
        "\n",
        "        # Save restaurant details\n",
        "        with open(\"avartana_details.json\", \"w\") as f:\n",
        "            json.dump(restaurant_details, f, indent=2)\n",
        "\n",
        "        # Display sample menu items\n",
        "        print(f\"\\nExtracted {len(menu_items)} menu items. Sample items:\")\n",
        "        print(menu_df.head(10))\n",
        "        print(\"\\nData saved to 'avartana_menu.csv', 'avartana_menu.json', and 'avartana_details.json'\")\n",
        "\n",
        "        return restaurant_details, menu_items\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error in main scraping function: {e}\")\n",
        "        return None, None\n",
        "\n",
        "# Run the scraper\n",
        "restaurant_details, menu_items = scrape_avartana()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: download restaurant details\n",
        "\n",
        "from google.colab import files\n",
        "files.download('avartana_menu.csv')\n",
        "files.download('avartana_menu.json')\n",
        "files.download('avartana_details.json')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "2sEb-YcXC4qg",
        "outputId": "1cd0a160-ba2a-4fec-e85f-75f3ca4ef852"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_f583449b-0b9b-49c5-9df1-e2e3f4715e5b\", \"avartana_menu.csv\", 732)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_90d5dee1-2d69-48fc-95c7-7c0fcfc3498c\", \"avartana_menu.json\", 1651)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_04f47afe-2f67-4038-afb1-3637d308359b\", \"avartana_details.json\", 776)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7kz4fP-yDIAO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}