{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        " !pip install requests beautifulsoup4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_s6SF0jOzA6v",
        "outputId": "a8670e8f-edfd-468b-d5c4-423fd3e975ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (4.13.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.1.31)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4) (2.6)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4) (4.13.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "url = \"https://www.tajhotels.com/en-in/hotels/taj-palace-new-delhi/restaurants/capital-kitchen\"\n",
        "headers = {\n",
        "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
        "}\n",
        "\n",
        "response = requests.get(url, headers=headers)\n",
        "soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "# Find the specific div using aria-label\n",
        "food_facilities_div = soup.find('div', {'aria-label': 'hotel-dine-in-food-facilities'})\n",
        "\n",
        "if food_facilities_div:\n",
        "    print(food_facilities_div.get_text(separator='\\n', strip=True))\n",
        "else:\n",
        "    print(\"Div not found or content is loaded dynamically.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NdfZFSt4zBTZ",
        "outputId": "86b5d01b-393d-41c6-a2c1-846094c5d944"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BREAKFAST\n",
            "6:30 am to 10:30 am\n",
            "LUNCH\n",
            "12:30 pm to 2:45 pm\n",
            "DINNER\n",
            "7:00 pm to 11:00 pm\n",
            "CUISINE\n",
            "Multi-Cuisine\n",
            "DRESS CODE\n",
            "Smart Casual\n",
            "Menu\n",
            "DOWNLOAD\n",
            "CONTACT\n",
            "2 Sardar Patel Marg Diplomatic Enclave, New Delhi, 110021, India\n",
            "tphcapitalkitchen.del@tajhotels.com​\n",
            "+91 11665 03721\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "\n",
        "url = \"https://www.tajhotels.com/en-in/hotels/taj-palace-new-delhi/restaurants/capital-kitchen\"\n",
        "headers = {\n",
        "    'User-Agent': 'Mozilla/5.0'\n",
        "}\n",
        "\n",
        "response = requests.get(url, headers=headers)\n",
        "soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "# Find all links ending with .pdf\n",
        "pdf_links = []\n",
        "for a in soup.find_all('a', href=True):\n",
        "    if a['href'].endswith('.pdf'):\n",
        "        link = a['href']\n",
        "        if not link.startswith('http'):\n",
        "            link = \"https://www.ihcltata.com\" + link\n",
        "        pdf_links.append(link)\n",
        "\n",
        "# Fallback: Use regex to find any PDF links in the HTML\n",
        "if not pdf_links:\n",
        "    matches = re.findall(r'href=[\\'\"]?([^\\'\" >]+\\.pdf)', response.text)\n",
        "    for link in matches:\n",
        "        if not link.startswith('http'):\n",
        "            link = \"https://www.ihcltata.com\" + link\n",
        "        pdf_links.append(link)\n",
        "\n",
        "print(\"Menu PDF Links found:\")\n",
        "for link in pdf_links:\n",
        "    print(link)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pSvfWiw8zDmc",
        "outputId": "57ac7f7b-1878-44c9-d378-6c34646dab3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Menu PDF Links found:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required libraries\n",
        "!pip install requests beautifulsoup4 PyPDF2 pandas\n",
        "\n",
        "# Import necessary libraries\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import PyPDF2\n",
        "import io\n",
        "import re\n",
        "import pandas as pd\n",
        "import json\n",
        "\n",
        "# 1. Function to scrape restaurant details from the website\n",
        "def scrape_restaurant_details():\n",
        "    url = \"https://www.tajhotels.com/en-in/hotels/taj-palace-new-delhi/restaurants/capital-kitchen\"\n",
        "    headers = {\n",
        "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        response = requests.get(url, headers=headers)\n",
        "        soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "        # Extract restaurant name\n",
        "        name = \"Capital Kitchen\"\n",
        "        name_tag = soup.find('h1')\n",
        "        if name_tag:\n",
        "            name = name_tag.text.strip()\n",
        "\n",
        "        # Extract location\n",
        "        location = \"2 Sardar Patel Marg Diplomatic Enclave, New Delhi, 110021, India\"\n",
        "        location_div = soup.find(string=re.compile(\"CONTACT\", re.IGNORECASE))\n",
        "        if location_div:\n",
        "            location_p = location_div.find_next('p')\n",
        "            if location_p:\n",
        "                location = location_p.text.strip()\n",
        "\n",
        "        # Extract contact information\n",
        "        contact = {\n",
        "            \"phone\": \"+91 11665 03721\",\n",
        "            \"email\": \"tphcapitalkitchen.del@tajhotels.com\"\n",
        "        }\n",
        "\n",
        "        email_a = soup.find('a', href=lambda href: href and 'mailto:' in href)\n",
        "        if email_a:\n",
        "            contact[\"email\"] = email_a.text.strip()\n",
        "\n",
        "        phone_a = soup.find('a', href=lambda href: href and 'tel:' in href)\n",
        "        if phone_a:\n",
        "            contact[\"phone\"] = phone_a.text.strip()\n",
        "\n",
        "        # Extract timings\n",
        "        timings = {\n",
        "            \"breakfast\": \"6:30 am to 10:30 am\",\n",
        "            \"lunch\": \"12:30 pm to 2:45 pm\",\n",
        "            \"dinner\": \"7:00 pm to 11:00 pm\"\n",
        "        }\n",
        "\n",
        "        breakfast = soup.find(string=re.compile(\"BREAKFAST\", re.IGNORECASE))\n",
        "        if breakfast:\n",
        "            breakfast_p = breakfast.find_next('p')\n",
        "            if breakfast_p:\n",
        "                timings[\"breakfast\"] = breakfast_p.text.strip()\n",
        "\n",
        "        lunch = soup.find(string=re.compile(\"LUNCH\", re.IGNORECASE))\n",
        "        if lunch:\n",
        "            lunch_p = lunch.find_next('p')\n",
        "            if lunch_p:\n",
        "                timings[\"lunch\"] = lunch_p.text.strip()\n",
        "\n",
        "        dinner = soup.find(string=re.compile(\"DINNER\", re.IGNORECASE))\n",
        "        if dinner:\n",
        "            dinner_p = dinner.find_next('p')\n",
        "            if dinner_p:\n",
        "                timings[\"dinner\"] = dinner_p.text.strip()\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error scraping website: {e}\")\n",
        "        print(\"Using default values...\")\n",
        "\n",
        "    # Use the direct menu URL from search results\n",
        "    menu_url = \"https://www.ihcltata.com/content/dam/luxury/hotels/taj-palace-delhi/documents/Capital-Kitchen.pdf\"\n",
        "\n",
        "    return {\n",
        "        \"name\": name,\n",
        "        \"location\": location,\n",
        "        \"contact\": contact,\n",
        "        \"timings\": timings,\n",
        "        \"menu_url\": menu_url\n",
        "    }\n",
        "\n",
        "# 2. Function to download and extract menu information from PDF\n",
        "def extract_menu_from_pdf(pdf_url):\n",
        "    print(f\"Downloading PDF from: {pdf_url}\")\n",
        "\n",
        "    try:\n",
        "        response = requests.get(pdf_url)\n",
        "\n",
        "        if response.status_code == 200:\n",
        "            # Save the PDF locally\n",
        "            with open(\"menu.pdf\", \"wb\") as f:\n",
        "                f.write(response.content)\n",
        "\n",
        "            print(\"PDF downloaded successfully. Extracting text...\")\n",
        "\n",
        "            # Extract text using PyPDF2\n",
        "            pdf_file = io.BytesIO(response.content)\n",
        "            pdf_reader = PyPDF2.PdfReader(pdf_file)\n",
        "\n",
        "            # Extract text from all pages\n",
        "            menu_text = \"\"\n",
        "            for page in pdf_reader.pages:\n",
        "                menu_text += page.extract_text() + \"\\n\\n\"\n",
        "\n",
        "            # Process the text to extract menu items\n",
        "            menu_items = []\n",
        "            current_section = \"Menu Items\"\n",
        "            lines = menu_text.split('\\n')\n",
        "\n",
        "            for i, line in enumerate(lines):\n",
        "                line = line.strip()\n",
        "                if not line:\n",
        "                    continue\n",
        "\n",
        "                # Check if this line could be a section header (all caps, no price)\n",
        "                if line.isupper() and not re.search(r'\\d{3,4}$', line):\n",
        "                    current_section = line\n",
        "                    continue\n",
        "\n",
        "                # Look for menu items with prices (item followed by 3-4 digit number)\n",
        "                price_match = re.search(r'(\\d{3,4})$', line)\n",
        "                if price_match:\n",
        "                    price = price_match.group(1)\n",
        "                    # Extract the item name (everything before the price)\n",
        "                    item_name = line[:line.rfind(price)].strip()\n",
        "\n",
        "                    # Look for description in the next line\n",
        "                    description = \"\"\n",
        "                    if i + 1 < len(lines):\n",
        "                        next_line = lines[i + 1].strip()\n",
        "                        # If next line doesn't have a price and isn't a section header, it's likely a description\n",
        "                        if not re.search(r'\\d{3,4}$', next_line) and not next_line.isupper() and next_line:\n",
        "                            description = next_line\n",
        "\n",
        "                    menu_items.append({\n",
        "                        \"section\": current_section,\n",
        "                        \"item\": item_name,\n",
        "                        \"price\": \"₹\" + price,\n",
        "                        \"description\": description\n",
        "                    })\n",
        "\n",
        "            return menu_items\n",
        "        else:\n",
        "            print(f\"Failed to download PDF. Status code: {response.status_code}\")\n",
        "            return None\n",
        "    except Exception as e:\n",
        "        print(f\"Error extracting menu: {e}\")\n",
        "        return None\n",
        "\n",
        "# Main function to run the scraping and display results\n",
        "def scrape_capital_kitchen():\n",
        "    print(\"==== Capital Kitchen Restaurant Scraper ====\")\n",
        "\n",
        "    # Get restaurant details\n",
        "    restaurant_details = scrape_restaurant_details()\n",
        "\n",
        "    # Display restaurant details\n",
        "    print(\"\\n=== Restaurant Details ===\")\n",
        "    print(f\"Name: {restaurant_details['name']}\")\n",
        "    print(f\"Location: {restaurant_details['location']}\")\n",
        "    print(f\"Contact: {restaurant_details['contact']['phone']} | {restaurant_details['contact']['email']}\")\n",
        "    print(\"\\nTimings:\")\n",
        "    print(f\"  Breakfast: {restaurant_details['timings']['breakfast']}\")\n",
        "    print(f\"  Lunch: {restaurant_details['timings']['lunch']}\")\n",
        "    print(f\"  Dinner: {restaurant_details['timings']['dinner']}\")\n",
        "    print(f\"\\nMenu URL: {restaurant_details['menu_url']}\")\n",
        "\n",
        "    # Extract menu from PDF\n",
        "    print(\"\\nExtracting menu from PDF...\")\n",
        "    menu_items = extract_menu_from_pdf(restaurant_details['menu_url'])\n",
        "\n",
        "    if menu_items:\n",
        "        # Create DataFrame to display menu items\n",
        "        menu_df = pd.DataFrame(menu_items)\n",
        "\n",
        "        # Save to CSV and JSON\n",
        "        menu_df.to_csv(\"capital_kitchen_menu.csv\", index=False)\n",
        "        with open(\"capital_kitchen_menu.json\", \"w\") as f:\n",
        "            json.dump(menu_items, f, indent=2)\n",
        "\n",
        "        # Display sample items\n",
        "        print(f\"\\nExtracted {len(menu_items)} menu items. Sample items:\")\n",
        "        print(menu_df.head(10))\n",
        "        print(\"\\nData saved to 'capital_kitchen_menu.csv' and 'capital_kitchen_menu.json'\")\n",
        "    else:\n",
        "        print(\"Failed to extract menu items.\")\n",
        "\n",
        "    # Save restaurant details\n",
        "    with open(\"restaurant_details.json\", \"w\") as f:\n",
        "        json.dump(restaurant_details, f, indent=2)\n",
        "\n",
        "    print(\"Restaurant details saved to 'restaurant_details.json'\")\n",
        "\n",
        "    return restaurant_details, menu_items\n",
        "\n",
        "# Run the scraper\n",
        "restaurant_details, menu_items = scrape_capital_kitchen()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gT4Q4O5y0iVk",
        "outputId": "3e85baea-e004-41f7-c9ab-7370548840b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (4.13.4)\n",
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.1.31)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4) (2.6)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4) (4.13.2)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyPDF2\n",
            "Successfully installed PyPDF2-3.0.1\n",
            "==== Capital Kitchen Restaurant Scraper ====\n",
            "\n",
            "=== Restaurant Details ===\n",
            "Name: Capital Kitchen\n",
            "Location: 2 Sardar Patel Marg Diplomatic Enclave, New Delhi, 110021, India\n",
            "Contact: 1-800-111-825 | reservations@ihcltata.com\n",
            "\n",
            "Timings:\n",
            "  Breakfast: 6:30 am to 10:30 am\n",
            "  Lunch: 12:30 pm to 2:45 pm\n",
            "  Dinner: 7:00 pm to 11:00 pm\n",
            "\n",
            "Menu URL: https://www.ihcltata.com/content/dam/luxury/hotels/taj-palace-delhi/documents/Capital-Kitchen.pdf\n",
            "\n",
            "Extracting menu from PDF...\n",
            "Downloading PDF from: https://www.ihcltata.com/content/dam/luxury/hotels/taj-palace-delhi/documents/Capital-Kitchen.pdf\n",
            "PDF downloaded successfully. Extracting text...\n",
            "\n",
            "Extracted 100 menu items. Sample items:\n",
            "      section                                               item  price  \\\n",
            "0  Menu Items  All prices are in Indian Rupees and subject to...  ₹1450   \n",
            "1  Menu Items                                    PIZZA PEPPERONI  ₹1450   \n",
            "2  Menu Items                           THE CAPITAL PIZZA 1450 /  ₹1150   \n",
            "3  Menu Items                           CLASSIC PIZZA MARGHERITA  ₹1150   \n",
            "4  Menu Items                                        PIZZA FUNGI  ₹1150   \n",
            "5  Menu Items  Assorted mushrooms, crushed tomatoes, crispy g...   ₹875   \n",
            "6  Menu Items                                        GREEK SALAD   ₹795   \n",
            "7  Menu Items                                 TUSCAN TOMATO SOUP   ₹625   \n",
            "8  Menu Items                             GOURMET CHICKEN BURGER  ₹1350   \n",
            "9  Menu Items                             CAJUN VEGETABLE BURGER  ₹1150   \n",
            "\n",
            "                                         description  \n",
            "0  Calamari, shrimp, smoked salmon, con/f_it garl...  \n",
            "1  Pork pepperoni, crushed tomatoes, mozzarella, ...  \n",
            "2  Barbecued chicken, red onion, fresh coriander,...  \n",
            "3              Mozzarella, fresh basil, tomato sauce  \n",
            "4                                                     \n",
            "5  Romaine lettuce, crispy bacon, grilled chicken...  \n",
            "6  Herb-marinated feta, cucumber, tomatoes, Kalam...  \n",
            "7  A heart-warming roma tomato soup, served with ...  \n",
            "8  Juicy chicken patty topped with cheddar, crisp...  \n",
            "9  Cajun-spiced vegetable patty, gherkins, sliced...  \n",
            "\n",
            "Data saved to 'capital_kitchen_menu.csv' and 'capital_kitchen_menu.json'\n",
            "Restaurant details saved to 'restaurant_details.json'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6fZcllya3Itg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}